2/3*(-0.1339746^2) + 4/3*(-0.1339746) + 2/3
2/3*(-0.1339746)^2 + 4/3*(-0.1339746) + 2/3
0.875/3 - 0.75 + 0.5
1/24
mean(score*ni)
score <- c(0,1,2,3,4,5)
ni <- c(10,8,12,9,7,3)
mean(score*ni)
score*ni
mean(score*ni,lenght(ni))
p_normal_greater_equal(6.3,6, 2/sqrt(25))
p_normal_lower_equal(6.3,6, 2/sqrt(25))
p_normal_greater_equal(15, 12, sqrt(16))
p_normal_greater_equal(14, 12, sqrt(16))
p_normal_greater <- function(x, mean, sd){
return(pnorm(x,mean,sd,lower.tail = FALSE))
}
# function for combinatory numbers, params n=totalNumber, x=desiredNumber
combinatory_number <- function(n,x){
return( factorial(n) / ( factorial(x) * factorial(n-x) ) )
}
# binomial distribution for discrete random number
binomial_discrete <- function(n,p,x){
return( combinatory_number(n,x) * p^x * (1-p)^(n-x) )
}
# binomial distribution for cumulative random number excluding the threshold
binomial_cumulative_less <- function(n,p,x){
total_number <- 0
for (xi in 0:(x-1)) {
total_number <- total_number + binomial_discrete(n,p,xi)
}
return(total_number)
}
# binomial distribution for cumulative random number including the threshold
binomial_cumulative_equal <- function(n,p,x){
return ( binomial_cumulative_less(n,p,x) + binomial_discrete(n,p,x))
}
# TO DO GREATER
#moments
binomial_moments <- function(n,p){
# here I need to add a condition
mean <- n * p
variance <- n * p * (1 - p)
return(list(mean = mean, variance = variance))
}
#--------------------------------------
# POISSON DISTRIBUTION
# poisson distribution for discrete random number
poisson_discrete <- function(lambda, x){
# Returns the probability P(X=x) on the standard scale
return(dpois(x, lambda, log = FALSE))
}
# poisson distribution for cumulative random number excluding the threshold
poisson_cumulative_less_equal <- function(lambda, x){
return(ppois(q=x,lambda = lambda))
}
# poisson distribution for cumulative random number includin the threshold
poisson_cumulative_less <- function(lambda, x){
return(poisson_cumulative_less_equal(lambda,x) - poisson_discrete(lambda,x))
}
# poisson distribution for cumulative random number includin the threshold
poisson_cumulative_greater <- function(lambda, x){
return(ppois(q=x,lambda = lambda, lower.tail = FALSE))
}
#moments in the second file
#--------------------------------------
# CONTINUOS VALUES - DISTRIBUTIONS
#--------------------------------------
# NORMAL DISTRIBUTIONS
# X >= q - when I am searching for greater value
p_normal_greater <- function(x, mean, sd){
return(pnorm(x,mean,sd,lower.tail = FALSE))
}
# X <= q - when I am searching for smaller or equal value
p_normal_lower_equal <- function(x, mean, sd){
return(pnorm(x,mean,sd))
}
# X < q - when I am searching for smaller value
p_normal_lower <- function(x, mean, sd){
return(pnorm(x-1,mean,sd))
}
p_normal_interval <- function(a,b,mean,sd){
prob <- p_normal_greater_equal(a,mean,sd) - p_normal_greater_equal(b,mean,sd)
return(prob)
}
p_normal_greater(14, 12, sqrt(16))
p_normal_greater(14, 12, sqrt(16)/sqrt(9))
16/9
t-student <- function(n,s,diff){
df <- n - 1
SE <- s / sqrt(n)
t_stat <- difference / SE
probability <- pt(t_stat, df = df) - pt(-t_stat, df = df)
cat("Standard Error (SE):", SE, "\n")
cat("T-statistic:", t_stat, "\n")
cat("Required Probability:", probability, "\n")
return(probability)
}
t_student <- function(n,s,diff){
df <- n - 1
SE <- s / sqrt(n)
t_stat <- difference / SE
probability <- pt(t_stat, df = df) - pt(-t_stat, df = df)
cat("Standard Error (SE):", SE, "\n")
cat("T-statistic:", t_stat, "\n")
cat("Required Probability:", probability, "\n")
return(probability)
}
t_student <- function(n,sd,diff){
df <- n - 1
SE <- s / sqrt(n)
t_stat <- difference / SE
probability <- pt(t_stat, df = df) - pt(-t_stat, df = df)
cat("Standard Error (SE):", SE, "\n")
cat("T-statistic:", t_stat, "\n")
cat("Required Probability:", probability, "\n")
return(probability)
}
t_student(16,10.85,8)
t_student <- function(n,sd,diff){
df <- n - 1
SE <- sd / sqrt(n)
t_stat <- difference / SE
probability <- pt(t_stat, df = df) - pt(-t_stat, df = df)
cat("Standard Error (SE):", SE, "\n")
cat("T-statistic:", t_stat, "\n")
cat("Required Probability:", probability, "\n")
return(probability)
}
t_student(16,10.85,8)
t_student <- function(n,sd,difference){
df <- n - 1
SE <- sd / sqrt(n)
t_stat <- difference / SE
probability <- pt(t_stat, df = df) - pt(-t_stat, df = df)
cat("Standard Error (SE):", SE, "\n")
cat("T-statistic:", t_stat, "\n")
cat("Required Probability:", probability, "\n")
return(probability)
}
t_student(16,10.85,8)
standart_deviation = 1200^2; #sigma
number_of_samples = 25
sample_variance = 2500
threshold = (number_of_samples * sample_variance) / standart_deviation
probability <- pchisq(threshold, df=number_of_samples, lower.tail = FALSE)
probability
#-----------------------------
# chi-square distribution
#-----------------------------
chi_square_greater <- function(n,sd, threshold){
# 1. Calculate Degrees of Freedom
df <- n - 1
# 2. Calculate the critical Chi-Square value
chi_sq_crit <- (df * s_sq_threshold) / sigma_sq
# 3. Calculate the probability: P(Chi-Square > chi_sq_crit)
# Using pchisq with lower.tail = FALSE gives the upper-tail probability
probability <- pchisq(chi_sq_crit, df = df, lower.tail = FALSE)
cat("Degrees of Freedom (df):", df, "\n")
cat("Critical Chi-Square Value:", chi_sq_crit, "\n")
cat("Required Probability P(s^2 > 2500):", probability, "\n")
return(probability)
}
chi_square_lower <- function(n,sd, threshold){
# 1. Calculate Degrees of Freedom
df <- n - 1
# 2. Calculate the critical Chi-Square value
chi_sq_crit <- (df * s_sq_threshold) / sigma_sq
# 3. Calculate the probability: P(Chi-Square > chi_sq_crit)
# Using pchisq with lower.tail = TRUE gives the down-tail probability
probability <- pchisq(chi_sq_crit, df = df, lower.tail = TRUE)
cat("Degrees of Freedom (df):", df, "\n")
cat("Critical Chi-Square Value:", chi_sq_crit, "\n")
cat("Required Probability P(s^2 > 2500):", probability, "\n")
return(probability)
}
chi_square_greater(25,1200,2500)
chi_square_greater(25,1200,2500)
i-square distribution
#-----------------------------
# chi-square distribution
#-----------------------------
chi_square_greater <- function(n,sd, threshold){
# 1. Calculate Degrees of Freedom
df <- n - 1
# 2. Calculate the critical Chi-Square value
chi_sq_crit <- (df * threshold) / sd
# 3. Calculate the probability: P(Chi-Square > chi_sq_crit)
# Using pchisq with lower.tail = FALSE gives the upper-tail probability
probability <- pchisq(chi_sq_crit, df = df, lower.tail = FALSE)
cat("Degrees of Freedom (df):", df, "\n")
cat("Critical Chi-Square Value:", chi_sq_crit, "\n")
cat("Required Probability P(s^2 > 2500):", probability, "\n")
return(probability)
}
chi_square_lower <- function(n,sd, threshold){
# 1. Calculate Degrees of Freedom
df <- n - 1
# 2. Calculate the critical Chi-Square value
chi_sq_crit <- (df * threshold) / sd
# 3. Calculate the probability: P(Chi-Square > chi_sq_crit)
# Using pchisq with lower.tail = TRUE gives the down-tail probability
probability <- pchisq(chi_sq_crit, df = df, lower.tail = TRUE)
cat("Degrees of Freedom (df):", df, "\n")
cat("Critical Chi-Square Value:", chi_sq_crit, "\n")
cat("Required Probability P(s^2 > 2500):", probability, "\n")
return(probability)
}
chi_square_greater(25,1200,2500)
chi_square_lower(25,1200,2500)
standart_deviation = 1200^2; #sigma
number_of_samples = 25
sample_variance = 2500
threshold = (number_of_samples * sample_variance) / standart_deviation
probability <- pchisq(threshold, df=number_of_samples-1, lower.tail = FALSE)
probability
chi_square_lower(25,1200^2,2500)
chi_square_greater(25,1200^2,2500)
n_A <- 500
p_hat_A <- 0.43
e <- qnorm(.975) * sqrt(pA * (1-pA) / nA)
nA <- 500
pA <- 0.43
e <- qnorm(.975) * sqrt(pA * (1-pA) / nA)
c(pA - e, pA + e)
nA <- 500
pA <- 0.43
e <- qnorm(0.975) * sqrt(pA * (1-pA) / nA)
c(pA - e, pA + e)
confidence_binomial <- function(n, p, z){
nA <- n
pA <- p
e <- qnorm(1-z) * sqrt(pA * (1-pA) / nA)
c(pA - e, pA + e)
}
nA <- 500
pA <- 0.43
z <- 0.025
confidence_binomial(nA,p,z)
nA <- 500
pA <- 0.43
z <- 0.025
confidence_binomial(nA,pA,z)
nA <- 300
pA <- 0.42
z <- 0.025
confidence_binomial(nA,pA,z)
p <- 27/150
n <- 150
z <- 0.025
confidence_binomial(n,p,z)
confidence_score_z <-function(z){
qnorm(1-z)
}
confidence_score_t <-function(z,n){
qt(1-z,n)
}
confidence_score_z <-function(z){
qnorm(1-z)
return(qnorm(1-z))
}
confidence_score_t <-function(z,n){
qt(1-z,n)
return(qt(1-z,n))
}
x <- c(2.2,2.66,2.74,3.41,2.46,2.96,3.34,
2.16,2.46,2.71,2.04,3.74,3.24,3.92,2.38,
2.82,2.2, 2.42,2.82,2.84,4.22,3.64,1.77,
3.44,1.53)
x_mean = mean(x)
standart_deviation <- sd(x)
n = length(x)
#official way how to get it in the photos
#t_student = 2.064
t_student = confidence_score_z(0.025, n-1)
x <- c(2.2,2.66,2.74,3.41,2.46,2.96,3.34,
2.16,2.46,2.71,2.04,3.74,3.24,3.92,2.38,
2.82,2.2, 2.42,2.82,2.84,4.22,3.64,1.77,
3.44,1.53)
x_mean = mean(x)
standart_deviation <- sd(x)
n = length(x)
#official way how to get it in the photos
#t_student = 2.064
t_student = confidence_score_t(0.025, n-1)
confidence_score_z <-function(z){
score <- qnorm(1-z)
cat("T score:", score, "\n")
return(score)
}
confidence_score_t <-function(z,n){
score <- qt(1-z,n)
cat("T score:", score, "\n")
return(score)
}
x <- c(2.2,2.66,2.74,3.41,2.46,2.96,3.34,
2.16,2.46,2.71,2.04,3.74,3.24,3.92,2.38,
2.82,2.2, 2.42,2.82,2.84,4.22,3.64,1.77,
3.44,1.53)
x_mean = mean(x)
standart_deviation <- sd(x)
n = length(x)
#official way how to get it in the photos
#t_student = 2.064
t_student = confidence_score_t(0.025, n-1)
x <- c(2.2,2.66,2.74,3.41,2.46,2.96,3.34,
2.16,2.46,2.71,2.04,3.74,3.24,3.92,2.38,
2.82,2.2, 2.42,2.82,2.84,4.22,3.64,1.77,
3.44,1.53)
x_mean = mean(x)
standart_deviation <- sd(x)
n = length(x)
#official way how to get it in the photos
#t_student = 2.064
t_student = confidence_score_t(0.025, n-1)
# n < 30, so we will use the formula bellow
l1 = x_mean - t_student * (standart_deviation) / sqrt(n)
l2 = x_mean + t_student * (standart_deviation) / sqrt(n)
# results:
l1
l2
temp_befor <- c(39.3, 39.7, 39.9, 40, 38.9, 39.7, 39.3)
temp_after <- c(38.1, 38, 38.3, 37.9, 38.7, 38.3, 37)
nA = length(temp_before)
temp_before <- c(39.3, 39.7, 39.9, 40, 38.9, 39.7, 39.3)
temp_after <- c(38.1, 38, 38.3, 37.9, 38.7, 38.3, 37)
nA = length(temp_before)
nB = length(temp_after)
nA + nB
temp_before <- c(39.3, 39.7, 39.9, 40, 38.9, 39.7, 39.3)
temp_after <- c(38.1, 38, 38.3, 37.9, 38.7, 38.3, 37)
nA = length(temp_before)
nB = length(temp_after)
var(temp_before)
var(temp_after)
temp_before <- c(39.3, 39.7, 39.9, 40, 38.9, 39.7, 39.3)
temp_after <- c(38.1, 38, 38.3, 37.9, 38.7, 38.3, 37)
nA = length(temp_before)
nB = length(temp_after)
meanA <- mean(temp_before)
meanB <- mean(temp_after)
meanA - meanB
temp_before <- c(39.3, 39.7, 39.9, 40, 38.9, 39.7, 39.3)
temp_after <- c(38.1, 38, 38.3, 37.9, 38.7, 38.3, 37)
nA = length(temp_before)
nB = length(temp_after)
meanA <- mean(temp_before)
meanB <- mean(temp_after)
meanA - meanB
t_interval <- t.test(x = temp_before,
y = temp_after,
conf.level = 0.90,
paired = TRUE)
temp_before <- c(39.3, 39.7, 39.9, 40, 38.9, 39.7, 39.3)
temp_after <- c(38.1, 38, 38.3, 37.9, 38.7, 38.3, 37)
nA = length(temp_before)
nB = length(temp_after)
meanA <- mean(temp_before)
meanB <- mean(temp_after)
meanA - meanB
t_interval <- t.test(x = temp_before,
y = temp_after,
conf.level = 0.90,
paired = TRUE)
t_interval
temp_before <- c(39.3, 39.7, 39.9, 40, 38.9, 39.7, 39.3)
temp_after <- c(38.1, 38, 38.3, 37.9, 38.7, 38.3, 37)
nA = length(temp_before)
nB = length(temp_after)
meanA <- mean(temp_before)
meanB <- mean(temp_after)
meanA - meanB
t_interval_welch <- t.test(x = temp_before,
y = temp_after,
conf.level = 0.90,
var.equal = FALSE,
paired = FALSE)
t_interval_welch
confidence_binomial(200,110/200,0.005)
n <- 200 # Number of tosses
X <- 110 # Number of heads obtained
p_
n <- 200 # Number of tosses
X <- 110 # Number of heads obtained
p_hat <- X / n # Observed proportion of heads
# Confidence level and critical Z value for a 99%confidence interval
alpha <- 0.01
Z_alpha_2 <- qnorm(1 - alpha / 2)
# Calculate the standard error of the proportion
std_error <- sqrt((p_hat * (1 - p_hat)) / n)
# Calculate the confidence interval
lower_bound <- p_hat - Z_alpha_2 * std_error
upper_bound <- p_hat + Z_alpha_2 * std_error
# Display the confidence interval
cat("99%␣Confidence␣Interval:[", lower_bound, "",, upper_bound, "]\n")
n <- 200 # Number of tosses
X <- 110 # Number of heads obtained
p_hat <- X / n # Observed proportion of heads
# Confidence level and critical Z value for a 99%confidence interval
alpha <- 0.01
Z_alpha_2 <- qnorm(1 - alpha / 2)
# Calculate the standard error of the proportion
std_error <- sqrt((p_hat * (1 - p_hat)) / n)
# Calculate the confidence interval
lower_bound <- p_hat - Z_alpha_2 * std_error
upper_bound <- p_hat + Z_alpha_2 * std_error
# Display the confidence interval
lower_bound
upper_bound
confidence_binomial(200,110/200,0.005)
n = 144
mean_x = 160
variance = 100
z1 = 0.05
z2 = 0.1
mean_x - confidence_score_z(z1/2)*(sqrt(variance)/sqrt(n))
mean_x + confidence_score_z(z1/2)*(sqrt(variance)/sqrt(n))
#with z2
mean_x - confidence_score_z(z2/2)*(sqrt(variance)/sqrt(n))
mean_x + confidence_score_z(z2/2)*(sqrt(variance)/sqrt(n))
# 4. Calculate Required Sample Size (n)
Target_ME <- 1.2
n_required <- ceiling((confidence_score_z(z2/2) * sqrt(variance) / Target_ME)^2)
additional_n <- n_required - n
cat("Required Sample Size (n):", n_required, "\n")
cat("Additional Observations needed:", additional_n, "\n")
confidence_binomial(200,110/200,0.005)
x <- c(2.2,2.66,2.74,3.41,2.46,2.96,3.34,
2.16,2.46,2.71,2.04,3.74,3.24,3.92,2.38,
2.82,2.2, 2.42,2.82,2.84,4.22,3.64,1.77,
3.44,1.53)
length(x)
x <- c(2.2,2.66,2.74,3.41,2.46,2.96,3.34,
2.16,2.46,2.71,2.04,3.74,3.24,3.92,2.38,
2.82,2.2, 2.42,2.82,2.84,4.22,3.64,1.77,
3.44,1.53)
n <- length(x)
mu = 2
mean_x = mean(x)
result <- (abs(mean_x - mu))/(sd(x)/sqrt(n))
result
x <- c(2.2,2.66,2.74,3.41,2.46,2.96,3.34,
2.16,2.46,2.71,2.04,3.74,3.24,3.92,2.38,
2.82,2.2, 2.42,2.82,2.84,4.22,3.64,1.77,
3.44,1.53)
n <- length(x)
mu = 2
mean_x = mean(x)
result <- (abs(mean_x - mu))/(sd(x)/sqrt(n))
result
confidence_score_t(0.0025, n-1)
t.test(x, mu=2, alternative = "two.side", coef.leve = 0.95)
binomial_discrete(10,0.17,3)
dbinom(3, size = 10, prob = 0.17)
pbinom(4,10,0.7)
binomial_cumulative_equal(10,0.7,4)
binomial_cumulative_less(10,0.5,2)
binomial_cumulative_less(10,0.5,2)
pbinom(2,10,0.5)
pbinom(1,10,0.5)
binomial_cumulative_less(10,0.5,2)
binomial_discrete(10,0.17,3)
combinatory_number(4,3)
combinatory_number(3,4)
combinatory_number(5,4)
combinatory_number(10,4)
choose(10,4)
devtools::install_github("gcardas/cardasStat")
library(cardasStat)
remove.packages("cardasStat")
devtools::install_github("gcardas/cardasStat")
library(cardasStat)
remove.packages(cardasStat)
remove.packages("cardasStat")
devtools::install_github("gcardas/cardasStat")
library(cardasStat)
rm -rf /Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/cardasStat
left <- abs(sample_mean - null) /(sd/sqrt(n))
alpha <- 0.05
null <- 150000
n <- 50
sample_mean <- 189000
sd <- 80000
left <- abs(sample_mean - null) /(sd/sqrt(n))
alpha <- 0.05
null <- 150000
n <- 50
sample_mean <- 189000
sd <- 80000
left <- abs(sample_mean - null) /(sd/sqrt(n))
confidence_score_z(a/2)
a <- 0.05
null <- 150000
n <- 50
sample_mean <- 189000
sd <- 80000
left <- abs(sample_mean - null) /(sd/sqrt(n))
confidence_score_z(a/2)
a <- 0.05
null <- 150000
n <- 50
sample_mean <- 189000
sd <- 80000
left <- abs(sample_mean - null) /(sd/sqrt(n))
confidence_score_z(a/2)
left > confidence_score_z(a/2)
devtools::install_github("gcardas/cardasStat", force = TRUE)
devtools::install_github("gcardas/cardasStat", force = TRUE)
devtools::install_github("gcardas/cardasStat")
library(cardasStat)
remove.packages("cardasStat")
.libPaths()
